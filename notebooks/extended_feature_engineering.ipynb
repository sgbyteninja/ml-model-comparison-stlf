{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e533728",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7590feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bc841f",
   "metadata": {},
   "source": [
    "## Load the Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53308a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "interim_folder = \"../data/interim\"\n",
    "processed_folder = \"../data/processed\"\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Load preprocessed base data\n",
    "cleaned_df = pd.read_csv(\n",
    "    os.path.join(interim_folder, \"cleaned_df.csv\"),\n",
    "    sep=\";\",\n",
    "    decimal=\",\"\n",
    ")\n",
    "\n",
    "# Ensure timestamp is datetime and data is sorted\n",
    "cleaned_df[\"timestamp\"] = pd.to_datetime(cleaned_df[\"timestamp\"])\n",
    "cleaned_df = cleaned_df.sort_values(\"timestamp\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222a461",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Tuned Lag Features Engineering\n",
    "To capture temporal dependencies and recurring consumption patterns, an extended set of lagged features is generated.  \n",
    "Each lag represents the electricity load observed a specific number of hours before the current timestamp, enabling the model to learn intraday, daily, and seasonal dynamics.\n",
    "\n",
    "- **Intraday lags (1–24 hours):** capture short-term dependencies and within-day load fluctuations.  \n",
    "- **Multi-day lags (48–144 hours):** represent load values from two to six days earlier and capture short-term recurring patterns across days.  \n",
    "- **Weekly and multi-week lags (168, 336, 672 hours):** account for weekly and longer periodic consumption cycles.  \n",
    "- **Yearly lag (8760 hours):** captures annual seasonality by referencing the same hour one year earlier.\n",
    "\n",
    "This tuned feature set provides richer temporal context while preserving full comparability with the baseline preprocessing pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96a8fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intraday lags: 1..24 hours (exclude lag_5 if you don't want it)\n",
    "intraday_lags = [h for h in range(1, 25) if h != 5]\n",
    "\n",
    "# Daily lags up to one week: 2..6 days (48..144 hours)\n",
    "# (24 and 168 already covered by intraday_lags (24) and weekly lag (168))\n",
    "weekly_daily_lags = [24 * d for d in range(2, 7)]  # 48, 72, 96, 120, 144\n",
    "\n",
    "# Longer seasonal lags (keep what you already use)\n",
    "seasonal_lags = [168, 336, 672, 8760]\n",
    "\n",
    "# Final tuned lag list (unique + sorted)\n",
    "extended_lags = sorted(set(intraday_lags + weekly_daily_lags + seasonal_lags))\n",
    "\n",
    "# Create lagged features on the full time series\n",
    "for lag in extended_lags:\n",
    "    col = f\"lag_{lag}\"\n",
    "    if col not in cleaned_df.columns:\n",
    "        cleaned_df[col] = cleaned_df[\"load_MWh\"].shift(lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18955f17",
   "metadata": {},
   "source": [
    "## Adding Basic Calendar Features\n",
    "\n",
    "To account for regular consumption patterns driven by time-based behavior,  \n",
    "a set of simple calendar-related features is added to the dataset:\n",
    "\n",
    "- **Hour:** represents the hour of the day (0–23) and captures daily load fluctuations such as morning and evening peaks.  \n",
    "- **Weekday:** encodes the day of the week (0 = Monday, 6 = Sunday), allowing the model to differentiate between workdays and weekends.  \n",
    "- **Is_weekend:** a binary indicator (1 = Saturday/Sunday, 0 = weekday) used to distinguish lower weekend demand from higher weekday consumption.\n",
    "\n",
    "These features help the model learn typical daily and weekly cycles,  \n",
    "which are essential for accurately forecasting electricity load patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4782d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic calendar features\n",
    "cleaned_df[\"hour\"] = cleaned_df[\"timestamp\"].dt.hour\n",
    "cleaned_df[\"weekday\"] = cleaned_df[\"timestamp\"].dt.weekday\n",
    "cleaned_df[\"is_weekend\"] = (cleaned_df[\"weekday\"] >= 5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb74fbd4",
   "metadata": {},
   "source": [
    "### Removing Missing Values from Lagged Features\n",
    "\n",
    "Lagged feature creation introduces missing values at the beginning of the dataset,  \n",
    "as earlier timestamps do not have sufficient historical data to compute all lags  \n",
    "— especially for long-term features such as the one-year lag (8760 hours).  \n",
    "\n",
    "To ensure data consistency and prevent issues during model training,  \n",
    "rows containing any missing values are removed.  \n",
    "This operation effectively discards the initial portion of the dataset (approximately the first year),  \n",
    "leaving only complete observations with a full set of lagged and calendar features.\n",
    "\n",
    "The resulting dataset now contains clean, fully populated records  \n",
    "that can be reliably used for model training, validation, and forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "728ebda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended dataset shape: (26300, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>load_MWh</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_8</th>\n",
       "      <th>lag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_96</th>\n",
       "      <th>lag_120</th>\n",
       "      <th>lag_144</th>\n",
       "      <th>lag_168</th>\n",
       "      <th>lag_336</th>\n",
       "      <th>lag_672</th>\n",
       "      <th>lag_8760</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>41535.75</td>\n",
       "      <td>43915.50</td>\n",
       "      <td>45616.75</td>\n",
       "      <td>47461.50</td>\n",
       "      <td>48751.75</td>\n",
       "      <td>55785.75</td>\n",
       "      <td>58528.50</td>\n",
       "      <td>58442.50</td>\n",
       "      <td>55700.75</td>\n",
       "      <td>...</td>\n",
       "      <td>45682.0</td>\n",
       "      <td>44758.00</td>\n",
       "      <td>44051.5</td>\n",
       "      <td>41509.00</td>\n",
       "      <td>49242.25</td>\n",
       "      <td>54252.25</td>\n",
       "      <td>44569.25</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>40480.75</td>\n",
       "      <td>41535.75</td>\n",
       "      <td>43915.50</td>\n",
       "      <td>45616.75</td>\n",
       "      <td>47461.50</td>\n",
       "      <td>51849.00</td>\n",
       "      <td>55785.75</td>\n",
       "      <td>58528.50</td>\n",
       "      <td>58442.50</td>\n",
       "      <td>...</td>\n",
       "      <td>45020.5</td>\n",
       "      <td>43949.25</td>\n",
       "      <td>43100.5</td>\n",
       "      <td>40378.00</td>\n",
       "      <td>48546.75</td>\n",
       "      <td>52329.50</td>\n",
       "      <td>42806.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>39564.00</td>\n",
       "      <td>40480.75</td>\n",
       "      <td>41535.75</td>\n",
       "      <td>43915.50</td>\n",
       "      <td>45616.75</td>\n",
       "      <td>48751.75</td>\n",
       "      <td>51849.00</td>\n",
       "      <td>55785.75</td>\n",
       "      <td>58528.50</td>\n",
       "      <td>...</td>\n",
       "      <td>45397.0</td>\n",
       "      <td>44202.25</td>\n",
       "      <td>42820.5</td>\n",
       "      <td>40437.75</td>\n",
       "      <td>48432.00</td>\n",
       "      <td>51662.25</td>\n",
       "      <td>41049.75</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  load_MWh     lag_1     lag_2     lag_3     lag_4  \\\n",
       "0 2022-01-01 01:00:00  41535.75  43915.50  45616.75  47461.50  48751.75   \n",
       "1 2022-01-01 02:00:00  40480.75  41535.75  43915.50  45616.75  47461.50   \n",
       "2 2022-01-01 03:00:00  39564.00  40480.75  41535.75  43915.50  45616.75   \n",
       "\n",
       "      lag_6     lag_7     lag_8     lag_9  ...   lag_96   lag_120  lag_144  \\\n",
       "0  55785.75  58528.50  58442.50  55700.75  ...  45682.0  44758.00  44051.5   \n",
       "1  51849.00  55785.75  58528.50  58442.50  ...  45020.5  43949.25  43100.5   \n",
       "2  48751.75  51849.00  55785.75  58528.50  ...  45397.0  44202.25  42820.5   \n",
       "\n",
       "    lag_168   lag_336   lag_672  lag_8760  hour  weekday  is_weekend  \n",
       "0  41509.00  49242.25  54252.25  44569.25     1        5           1  \n",
       "1  40378.00  48546.75  52329.50  42806.00     2        5           1  \n",
       "2  40437.75  48432.00  51662.25  41049.75     3        5           1  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lag creation introduces NaNs at the beginning (up to max lag)\n",
    "cleaned_df_extended = cleaned_df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Extended dataset shape:\", cleaned_df_extended.shape)\n",
    "cleaned_df_extended.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772d198",
   "metadata": {},
   "source": [
    "## Train–Test Split\n",
    "\n",
    "To prepare the dataset for model development and evaluation, the full time series is chronologically divided into a **training/validation set** and a **test set**.  \n",
    "This ensures that future information is not used for model training, maintaining the temporal integrity of the forecasting task.\n",
    "\n",
    "- **Training/Validation set:** Includes all data from January 2022 to December 2023.  \n",
    "  These observations are used to train the forecasting models and tune their hyperparameters.  \n",
    "\n",
    "- **Test set:** Contains data from January to December 2024.  \n",
    "  This portion of the dataset is completely unseen during training and is used for the final model evaluation and recursive forecasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c8f679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended Train/Validation period: 2022-01-01 01:00:00 → 2023-12-31 23:00:00\n",
      "Extended Test period:            2024-01-01 00:00:00 → 2024-12-31 23:00:00\n",
      "Extended Train/Validation shape: (17517, 37)\n",
      "Extended Test shape:             (8783, 37)\n",
      "Saved extended_train_val_df to: ../data/processed/train_val_df_extended.csv\n",
      "Saved extended_test_df to:../data/processed/test_df_extended.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure correct ordering and datetime format (already done above, but safe)\n",
    "cleaned_df_extended = cleaned_df_extended.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "cleaned_df_extended[\"timestamp\"] = pd.to_datetime(cleaned_df_extended[\"timestamp\"])\n",
    "\n",
    "test_start = \"2024-01-01\"\n",
    "\n",
    "train_val_df_extended = cleaned_df_extended[cleaned_df_extended[\"timestamp\"] < test_start].copy()\n",
    "test_df_extended      = cleaned_df_extended[cleaned_df_extended[\"timestamp\"] >= test_start].copy()\n",
    "\n",
    "print(f\"Extended Train/Validation period: {train_val_df_extended['timestamp'].min()} → {train_val_df_extended['timestamp'].max()}\")\n",
    "print(f\"Extended Test period:            {test_df_extended['timestamp'].min()} → {test_df_extended['timestamp'].max()}\")\n",
    "print(f\"Extended Train/Validation shape: {train_val_df_extended.shape}\")\n",
    "print(f\"Extended Test shape:             {test_df_extended.shape}\")\n",
    "\n",
    "# Save the extended datasets\n",
    "processed_folder = \"../data/processed\"\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "train_val_path = os.path.join(processed_folder, \"train_val_df_extended.csv\")\n",
    "test_path = os.path.join(processed_folder, \"test_df_extended.csv\")\n",
    "\n",
    "train_val_df_extended.to_csv(train_val_path, sep=\";\", decimal=\",\", index=False)\n",
    "test_df_extended.to_csv(test_path, sep=\";\", decimal=\",\", index=False)\n",
    "\n",
    "print(f\"Saved extended_train_val_df to: {train_val_path}\")\n",
    "print(f\"Saved extended_test_df to:{test_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
